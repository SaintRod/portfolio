[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "Howdy.\nMy name is Santiago Rodriguez and I am a statistician, statistical programmer, machine learning practitioner, and a life-long learner.\nI enjoy traveling. Some of my favorite places to visit are Norway and Japan.\nThe best way to contact me is through LinkedIn."
  },
  {
    "objectID": "posts/other/study-guides.html",
    "href": "posts/other/study-guides.html",
    "title": "Study Guides",
    "section": "",
    "text": "Data structures and algorithms\nI find it helpful to make my notes available online so that I can access them from anywhere. The following notes are from lessons on data structures and algorithms.\n\ndata structures\nalgorithms\n\nThe course provided Python examples, and I replicated these examples using Julia and R.\n\nJulia\nPyton\nR",
    "crumbs": [
      "Other",
      "Study Guides"
    ]
  },
  {
    "objectID": "posts/projects/projects.html",
    "href": "posts/projects/projects.html",
    "title": "Projects",
    "section": "",
    "text": "This is the largest section, and the one hiring manager and recruiters will most likely be interested in.\nIn this section you’ll find code, output, and more! My interests span a wide range of topics, from building web apps to machine learning models.\nThe following are areas I’d like to explore further, presented in no particular order.\n\nRAG\ndeep learning\nauto diff\noptimization\nGenie in Julia\nShiny for Python\nbuild an API\ncausal ML",
    "crumbs": [
      "Projects"
    ]
  },
  {
    "objectID": "posts/projects/web-apps/tpwd.html",
    "href": "posts/projects/web-apps/tpwd.html",
    "title": "Texas Parks & Wildlife",
    "section": "",
    "text": "Years ago when I moved to Texas from South Florida I missed going fishing. I discovered that during winter months, Texas Parks & Wildlife (TPWD) stocks local fishing areas with trout. This was music to my ears. However, the static HTML table provided by TPWD wasn’t conducive to getting outdoors. The problem with the static table is it only provides the fishing area and the city, and it’s too tedious to search each location individually on Google Maps for example. So, I built a Shiny app for myself and hosted it on ShinyApps.io (link). The app was successful and I was able to go fishing. The main goal of this version was to help me find the nearest fishing location and to be able to sort and filter locations.\nRecently, I decided to learn more about putting a Shiny app in production. I decided to focus on the TPWD trout POC I built years ago because I thought others could benefit from having a better interface to the trout stocking data. The scope of the app expanded beyond just the trout stocking data though as I realized that other TPWD resources were useful but not interactive. The static nature of the resources might deter some people from getting outdoors. So, I built this Shiny app.\nThe goal of this app is to help Texans interact with Texas Parks & Wildlife static online resources and to help Texans get outdoors.\n\nweb app code\ndata layer code\nwebsite\nShiny contest 2024\n\nThe web app is hosted on AWS using their free tier. Once the 12-months free expires, depending on the cost to maintain the website the link above my not exist. However, the code is readily available.\n\n\nFunctionality:\n\nInteractive tables\nCalculate drive time and distance\n\nTables:\n\nBoat ramps\nCatfish stocking information\nParks (list of state parks)\nTrout stocking information (new season begins in November)\nWildlife management areas\n\nHosting:\n\nAWS EC2 (free tier t2.micro)\n\nSoftware:\n\nShiny (R) built with the Rhino development framework\nHERE API for route calculation logic\nDocker",
    "crumbs": [
      "Projects",
      "Web Apps",
      "Texas Parks & Wildlife"
    ]
  },
  {
    "objectID": "posts/projects/web-apps/tpwd.html#technical-details",
    "href": "posts/projects/web-apps/tpwd.html#technical-details",
    "title": "Texas Parks & Wildlife",
    "section": "",
    "text": "Functionality:\n\nInteractive tables\nCalculate drive time and distance\n\nTables:\n\nBoat ramps\nCatfish stocking information\nParks (list of state parks)\nTrout stocking information (new season begins in November)\nWildlife management areas\n\nHosting:\n\nAWS EC2 (free tier t2.micro)\n\nSoftware:\n\nShiny (R) built with the Rhino development framework\nHERE API for route calculation logic\nDocker",
    "crumbs": [
      "Projects",
      "Web Apps",
      "Texas Parks & Wildlife"
    ]
  },
  {
    "objectID": "posts/projects/analyses/arxiv-stats-pkgs.html",
    "href": "posts/projects/analyses/arxiv-stats-pkgs.html",
    "title": "Arxiv Packages Analysis",
    "section": "",
    "text": "About\nAn analysis of Julia, Python, and R packages on the statistics section of Arxiv. The term “R package” had the most results, followed by Python then Julia.\n\nreport\ncode",
    "crumbs": [
      "Projects",
      "Analyses",
      "Arxiv Packages Analysis"
    ]
  },
  {
    "objectID": "posts/projects/analyses/internet-outage.html",
    "href": "posts/projects/analyses/internet-outage.html",
    "title": "Internet Outage Detection",
    "section": "",
    "text": "About\nYears ago I had a faulty internet router. The problem was I didn’t know it was the router yet. Eventually I set up a shell script to ping the router and log results. I analyzed the results and discovered that the router was the issue. I replaced the router with a Gryphon router - if you haven’t heard of it, I highly recommend it. Additionally, this was my first foray into the work of programming with Julia.\n\nreport",
    "crumbs": [
      "Projects",
      "Analyses",
      "Internet Outage Detection"
    ]
  },
  {
    "objectID": "posts/projects/stats/stats.html",
    "href": "posts/projects/stats/stats.html",
    "title": "Statistics",
    "section": "",
    "text": "Overview\n\nA primer on hypothesis testing, link",
    "crumbs": [
      "Projects",
      "Stats"
    ]
  },
  {
    "objectID": "posts/projects/tools/tools.html",
    "href": "posts/projects/tools/tools.html",
    "title": "Tools",
    "section": "",
    "text": "Overview\n\nA shell script that creates data analysis project templates, link",
    "crumbs": [
      "Projects",
      "Tools"
    ]
  },
  {
    "objectID": "posts/viz/viz.html",
    "href": "posts/viz/viz.html",
    "title": "Visualizations",
    "section": "",
    "text": "Overview\n\nA dashboard to track my job search in 2024, link",
    "crumbs": [
      "Projects",
      "Visualizations"
    ]
  },
  {
    "objectID": "posts/talks/r-in-energy.html",
    "href": "posts/talks/r-in-energy.html",
    "title": "R in Energy",
    "section": "",
    "text": "About\nSome time ago I had the great pleasure to share some of my work on functional data analysis.\nThe R in Energy meetup is a industry-focused data meetup for professionals working with R in the energy sector/ utilities industry. The meetups are hosted by Posit.\n\n\nLinks\n\nYouTube\nPresentation\n\n\n\nEmbedded\n\n\n\n\nR in Energy",
    "crumbs": [
      "Talks",
      "R in Energy"
    ]
  },
  {
    "objectID": "posts/blogs/fda.html",
    "href": "posts/blogs/fda.html",
    "title": "Functional Data Analysis",
    "section": "",
    "text": "About\nSince first learning about splines c.2020 I have been fascinated with functional data analysis (FDA).\nOver the years I’ve explored applications of FDA at work and for personal projects. I created this blog to collect these works and house them under one roof. The blog also provides me an avenue to share thoughts about the work that might not fit into the work itself, such as how the document was created, why I used certain software, etc.\nThe blog can be accessed here.",
    "crumbs": [
      "Blogs",
      "Functional Data Analysis"
    ]
  },
  {
    "objectID": "posts/blogs/blogs.html",
    "href": "posts/blogs/blogs.html",
    "title": "Blogs",
    "section": "",
    "text": "I enjoy writing. But I don’t enjoy paywalls. So, I write on open platforms, such as GitHub Pages or Quarto Pubs.\nIn this section you’ll find collections of writings. Enjoy!",
    "crumbs": [
      "Blogs"
    ]
  },
  {
    "objectID": "posts/talks/talks.html",
    "href": "posts/talks/talks.html",
    "title": "Talks",
    "section": "",
    "text": "In this section you’ll find speaking engagements. While there aren’t many, it’s something I wish to more of.",
    "crumbs": [
      "Talks"
    ]
  },
  {
    "objectID": "posts/viz/job-search-dashboard.html",
    "href": "posts/viz/job-search-dashboard.html",
    "title": "A Job Search Tracker",
    "section": "",
    "text": "In August my spouse and I welcomed a tiny human into our lives. Life was good. Then when I returned from parental leave I was informed that my team at Deloitte, about 20 people, would be let go.\nThis dashboard was created to track my job search post Deloitte. However, anyone can use the dashboard as the code is publicly available. The repo README provides instructions on how to do this. However, see below for a brief how-to.\n\ncode\ndashboard",
    "crumbs": [
      "Projects",
      "Visualizations",
      "A Job Search Tracker"
    ]
  },
  {
    "objectID": "posts/viz/job-search-dashboard.html#software",
    "href": "posts/viz/job-search-dashboard.html#software",
    "title": "A Job Search Tracker",
    "section": "1. Software",
    "text": "1. Software\nThe elements of the dashboard were created using Python 3.10.\nThe HTML output was created with Quarto - installation. Install the latest version as Qurto dashboards require a minimum version (1.4 I think).",
    "crumbs": [
      "Projects",
      "Visualizations",
      "A Job Search Tracker"
    ]
  },
  {
    "objectID": "posts/viz/job-search-dashboard.html#plot-backgrounds",
    "href": "posts/viz/job-search-dashboard.html#plot-backgrounds",
    "title": "A Job Search Tracker",
    "section": "2. Plot backgrounds",
    "text": "2. Plot backgrounds\nTo recreate the fun plot you will need two images:\n\nplot-background.png\nplot-point.png\n\nEnsure that the files are named exactly as the ones above.",
    "crumbs": [
      "Projects",
      "Visualizations",
      "A Job Search Tracker"
    ]
  },
  {
    "objectID": "posts/viz/job-search-dashboard.html#data",
    "href": "posts/viz/job-search-dashboard.html#data",
    "title": "A Job Search Tracker",
    "section": "3. Data",
    "text": "3. Data\n\nThe dashboard requires a CSV file saved in ./data/input\n\nYou can name the file whatever you want\nFor this example, let’s pretend the file is named elliott.csv\n\nThe file must contain the following columns\n\nThe data types are in the repo README\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndate\ncompany\nrole\nonsite\nhybrid\nremote\nsalary-low\nsalary-high\nrejected\ninterviewed\noffer\naccepted\n\n\n\n\n2024-10-09\nevil corp\nmr robot\n1\n\n\n50000\n1000000\n\n1\n1\n1",
    "crumbs": [
      "Projects",
      "Visualizations",
      "A Job Search Tracker"
    ]
  },
  {
    "objectID": "posts/viz/job-search-dashboard.html#python",
    "href": "posts/viz/job-search-dashboard.html#python",
    "title": "A Job Search Tracker",
    "section": "3. Python",
    "text": "3. Python\n\nopen a terminal and navigate to the project directory: cd ~/job-search\ncreate a virtual environment: python3.10 -m venv .venv\n\nI use pip, but uv is 🔥 right now (Oct 2024)\n\nactivate python source .venv/bin/activate\ninstall the project dependencies pip install -r requirements.txt\n\nNow, let’s check that everything is working. In the terminal run the following command to execute the testing logic: pytest.\nIf there are no errors then you’re safe to proceed to the next stage. If there are errors… open an issue 🤷",
    "crumbs": [
      "Projects",
      "Visualizations",
      "A Job Search Tracker"
    ]
  },
  {
    "objectID": "posts/viz/job-search-dashboard.html#quarto",
    "href": "posts/viz/job-search-dashboard.html#quarto",
    "title": "A Job Search Tracker",
    "section": "4. Quarto",
    "text": "4. Quarto\n\n_quarto.yml\n_quarto.yml is the control center of the Quarto project.\nHere is an example of a basic file. Customization is a bit outside our purposes. I encourage you to review thh Quarto docs.\nproject:\n  type: website\n  output-dir: public\n\nwebsite:\n  title: \"My Jobs Dashboard\"\n  site-url: \"\"\n  search: false\n  page-footer: \n    background: dark \n    right: Built with Quarto\n\nformat:\n  html:\n    theme: cosmo\n    css: styles.css\n    toc: false\n\n\nHosting/ Publishing or GitHub vs GitLab\nThe dashboard can be published on either GitHub or Gitlab. GitHub is a little easier and the Quarto docs illustrate how to publish on GitHub.\nI rendered this dashboard on GitLab because I’ve never done that before and I wanted to learn how.\nThe _quarto.yml specifies where to render the dashboard. Notice the output-dir under project.\n\non GitLab Pages the output dir is ./public\non GitHub Pages the output dir is ./docs\n\nUpdate output-dir accordingly.\nOne last note on GitLab Pages. GitLab uses runners to publish the dashboard, while GitHub has a GUI option.\nTo use GitLab you need a file named .gitlab-ci.yml. Contents below.\nimage: alpine:latest\n\nstages:\n- test\n- deploy\n\nsast:\n  stage: test\ninclude:\n- template: Security/SAST.gitlab-ci.yml\n\npages:\n  stage: deploy\n  script:\n    - echo \"Deploying GitLab Pages from the public directory\"\n  artifacts:\n    paths:\n      - public \n  only:\n    - main\n\n\nRendering\nAssuming you installed Quarto, let’s render the output.\nIn the terminal, type either:\n\nquarto render - generates output in the specified directory\nquarto preview - reactive programming so that changes are rendered live\n\nPreview is helpful if you’re actively working on stuff. When you preview the dashboard will open in a browser.\nWhile render only produces output. To view the output go to ./public/index.html on GitLab or ./docs/index.html on GitHub.",
    "crumbs": [
      "Projects",
      "Visualizations",
      "A Job Search Tracker"
    ]
  },
  {
    "objectID": "posts/projects/tools/mult-lang-proj-template.html",
    "href": "posts/projects/tools/mult-lang-proj-template.html",
    "title": "A Language agnostic project template",
    "section": "",
    "text": "About\nI present a handy shell script to automate and standardize data analysis project structures. Yes, several language-specific templates exist, but using them assumes the language for the project has already been chosen. Often when planning a project, I don’t select a language until later in the planning stage. Also, much of a project’s structure is language-agnostic so there’s no need to wait to lay the foundation.\n\ncode",
    "crumbs": [
      "Projects",
      "Tools",
      "A Language agnostic project template"
    ]
  },
  {
    "objectID": "posts/projects/stats/hypothesis-testing-primer.html",
    "href": "posts/projects/stats/hypothesis-testing-primer.html",
    "title": "A Primer on Hypothesis Testing",
    "section": "",
    "text": "Hypothesis testing\nDuring my tenure at Consumers Energy I was asked to help introduce the notion of testing. The focus was on marketing programs. This was a new-ish department and there were lots of opportunities.\nMy main focus was to build relationships with stakeholders and gently educate them about testing. Below is an example of some of the concepts and tools I used.\n\nreport",
    "crumbs": [
      "Projects",
      "Stats",
      "A Primer on Hypothesis Testing"
    ]
  },
  {
    "objectID": "posts/projects/analyses/analyses.html",
    "href": "posts/projects/analyses/analyses.html",
    "title": "Analyses",
    "section": "",
    "text": "Overview\n\nAn analysis of languages used to create statistics packages on Arxiv, link\nUsing Julia to analyze router packet data, link",
    "crumbs": [
      "Projects",
      "Analyses"
    ]
  },
  {
    "objectID": "posts/projects/web-apps/strat-sampling-tool.html",
    "href": "posts/projects/web-apps/strat-sampling-tool.html",
    "title": "Stratified Sampling",
    "section": "",
    "text": "About\nDuring my tenure at Consumers Energy, my sibling team was responsible for generating customer contact lists for Marketing teams. Mostly these lists were created via simple random sampling. However, there were some astute stakeholders that wanted to test if stratified sampling would yield more accurate results. Initially, the team accomplished this manually, but it was error-prone and onerous. So, I built a Shiny app for them to automate the task. Below is a replica of that work.\n\nwebapp\ncode",
    "crumbs": [
      "Projects",
      "Web Apps",
      "Stratified Sampling"
    ]
  },
  {
    "objectID": "posts/projects/web-apps/web-apps.html",
    "href": "posts/projects/web-apps/web-apps.html",
    "title": "Web Apps",
    "section": "",
    "text": "Overview\n\nA Texas Parks and Wildlife resource, link\nA tool to help create stratified samples, , link",
    "crumbs": [
      "Projects",
      "Web Apps"
    ]
  },
  {
    "objectID": "posts/other/other.html",
    "href": "posts/other/other.html",
    "title": "Other",
    "section": "",
    "text": "In this section you’ll find a collection of random things, from notes I took while reading a book or a video online.",
    "crumbs": [
      "Other"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Thank you for visiting!",
    "section": "",
    "text": "UAI"
  }
]